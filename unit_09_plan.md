# Unit 8: Large Sample Regression Theory 

In this unit you will learn about how linear models in general, and linear models fitted by the OLS regression algorithm in particular, produce estimates. 

To do so, you will synthesize several pieces from earlier units in the course. Namely, you will combine: 

- Covariance and correlation from your work with *random variables*;
- The *conditional expectation function* and its best linear approximation, the *BLP*;
- Core estimation theory about *bias*, *consistency*, and *efficiency*; 
- Convergence in distribution from the *Central Limit Theorem*; and, 
- Plug-in estimators from samples as population estimators. 

- The first session might take about **60** minutes to complete. 
- The second session might take between **90-120** minutes to complete. 

Let's get to work!

# Unit 9: Estimating Uncertainty of OLS Estimates 

In the last unit, you learned about how Ordinary Least Squares Regression -- OLS Regression -- is the plug-in estimator for the BLP. You learned about how to interpret the coefficients of a linear model, and how the OLS algorithm works to estimate the coefficients of the model. 

In this unit, you are going to learn about uncertainty estimates for these estimates. Because estimates of OLS regression coefficients are based on samples of data, different samples of data might generate different coefficients. We have two learning goals for this unit: 

1. To understand that OLS regression coefficients' standard errors are a produce of sampling, and to appreciate the similarity of this concept to measures of uncertainty from hypothesis in earlier units. 

2. To conduct appropriate tests within the Frequentist testing framework. These tests include tests for a null hypothsis for individual coefficients, and tests for a null hypothesis about an ensemble of coefficients. 

