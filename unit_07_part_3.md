# Part 3: Confidence Intervals, Practical Significance and p-Hacking 

In this section, which might take about an hour's time, you are going to learn about several concepts of hypothesis testing _in practice_. 

**First** you will learn about confidence intervals, which are regions produced from a sample and test that overlap the (unknown) _true_ population value with at some known rate. You'll read and watch a lecture about the concept, but there is a real risk of mis-interpreting these confidence intervals. This is where the careful language of statistics is at odds with the vernacular use of the term "confidence interval". 

**Second** you will learn about providing context for the results of parameter estimates. We will provide a few strategies for providing this context, but none of these will _always_ be correct. Understanding whether a result that is _statisticallY_ significant is _practically_ significant is very much shaped by context. 

**Third**, and finally, we will talk about issues concenring running many tests, but reporting only a subset of those tests. This is a problem that is present in academic research (sometimes deemed the "replication crisis"), but it is also very much a problem that is present in statistical work that is directed toward business decision-making.

