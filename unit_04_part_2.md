# Unit 4: Part 2

## Best Predictors (and their Linear Approximations)

In the second part of this week's work, which we anticipate might take you **90** minutes to read, take notes and attend lecture, introduces two of the core ideas in the course: 

1. With data, we can produce conditional statements that are *very good* summaries of an underlying joint distribution function. 
2. We can require that our conditional statements have a relatively simple form—linearity in the inputs—and show that in some cases these very simple functions can still serve as a *very good* summary of the underlying joint distribution function
